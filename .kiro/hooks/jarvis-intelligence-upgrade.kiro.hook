{
  "enabled": true,
  "name": "JARVIS Intelligence Upgrade",
  "description": "Monitors core AI components and automatically upgrades Jarvis with advanced intent extraction, semantic matching, contextual memory, multi-stage query decomposition, dynamic tool routing, sentiment analysis, knowledge graphs, and session awareness to create a real-life Iron Man JARVIS experience",
  "version": "1",
  "when": {
    "type": "fileCreated",
    "patterns": [
      "core/intent_classifier.py",
      "core/entity_extractor.py",
      "core/input_processor.py",
      "core/prompt_engine.py",
      "core/jarvis_brain.py",
      "core/response_generator.py",
      "core/nlp.py",
      "storage/contextual_memory.py",
      "core/decision_engine.py",
      "core/codeex_assistant.py",
      "D:\\CODEEX_L3\\core",
      "D:\\CODEEX_L3\\storage"
    ]
  },
  "then": {
    "type": "askAgent",
    "prompt": "The core AI architecture files have been modified. Analyze the changes and implement the following JARVIS upgrades:\n\n1. **Intent + Entity Extraction**: Enhance intent_classifier.py and entity_extractor.py with spaCy/Stanza NER, Rasa-style slot filling, and custom regex for CLI/modding syntax\n2. **Semantic Matching**: Integrate Sentence Transformers (all-MiniLM-L6-v2) in nlp.py for fuzzy matching and similarity-based routing\n3. **Magical Prompt Engineering**: Update prompt_engine.py with structured templates that maintain Codeex AI's warm, magical personality while being technically precise\n4. **Contextual Memory**: Enhance contextual_memory.py with LangChain memory modules for short-term (last 3 turns) and durable student preferences\n5. **Multi-Stage Query Decomposition**: Implement ReAct/PAL chains in jarvis_brain.py to break compound queries into sequential sub-intents\n6. **Dynamic Tool Routing**: Add MultiPromptChain/RouterChain to decision_engine.py for intelligent model/tool selection\n7. **Few-Shot Prompting**: Integrate FewShotPromptTemplate in prompt_engine.py with contextual examples\n8. **Clarification Loops**: Add confidence-based clarification prompts in response_generator.py\n9. **Input Sanitization**: Enhance input_processor.py with typo correction (symspellpy), normalization, and code block detection\n10. **Sentiment Analysis**: Add mood detection to adjust Jarvis's tone based on student frustration/encouragement needs\n11. **Knowledge Graph**: Implement concept tracking with networkx for learning path visualization\n12. **DSL Parsing**: Add custom parsers for domain-specific languages (Minecraft mods, etc.)\n13. **Session Summarization**: Implement end-of-session summaries with recall capabilities\n14. **Test Suite**: Create diverse test cases for casual queries, technical prompts, mixed-language inputs, and voice-to-text errors\nalso update brain by these \n1. Context Engineering with Persistent Memory\nUse structured memory to track:\n‚Ä¢ \tStudent goals, learning style, and past sessions\n‚Ä¢ \tPreferred explanation formats (e.g., analogies, diagrams, code)\n‚Ä¢ \tEmotional state or frustration signals\nTools: LangChain‚Äôs , , or your own Redis-backed memory store\nWhy it matters: Jarvis feels like a mentor who remembers and adapts.\n\nüß© 2. Context-Aware Retrieval-Augmented Generation (RAG)\nBuild a RAG pipeline that:\n‚Ä¢ \tUses semantic chunking (e.g., , ) to optimize token usage\n‚Ä¢ \tRetrieves relevant documents, configs, or modding guides from local or cloud sources\n‚Ä¢ \tInjects context into prompts dynamically\nWhy it matters: Jarvis can answer with precision, even on niche topics like Minecraft modding or CLI tools.\n\nüßô‚Äç‚ôÇÔ∏è 3. Adaptive Prompting Based on Input Complexity\nUse prompt templates that scale with input:\n‚Ä¢ \tSimple input ‚Üí direct response\n‚Ä¢ \tComplex input ‚Üí chain-of-thought reasoning + tool invocation\n‚Ä¢ \tAmbiguous input ‚Üí clarification loop\nWhy it matters: Jarvis feels intuitive and responsive, not robotic.\n\nüß™ 4. Self-Improving Feedback Loop\nLet Jarvis learn from interactions:\n‚Ä¢ \tTrack misunderstood queries and fallback triggers\n‚Ä¢ \tUse student feedback to refine intent classifiers\n‚Ä¢ \tPeriodically retrain local models or update prompt examples\nWhy it matters: Jarvis evolves with your classroom and student needs.\n\nüßµ 5. Multi-Turn Reasoning with Goal Tracking\nEnable Jarvis to:\n‚Ä¢ \tFollow multi-step plans (e.g., ‚ÄúExplain, then quiz, then summarize‚Äù)\n‚Ä¢ \tTrack progress across turns\n‚Ä¢ \tAsk ‚ÄúWould you like to continue?‚Äù or ‚ÄúShould I save this?‚Äù\nWhy it matters: Supports deeper learning and project-based workflows.\n\nüß† 6. Multimodal Input Understanding\nLet Jarvis interpret:\n‚Ä¢ \tScreenshots (via OpenCV + OCR)\n‚Ä¢ \tDiagrams or handwritten notes\n‚Ä¢ \tVoice input with Whisper or Google STT\nWhy it matters: Students can interact naturally‚Äîby showing, speaking, or sketching.\n\nüß∞ 7. Custom DSL + Config Validator\nFor modding and CLI workflows:\n‚Ä¢ \tBuild a parser for Minecraft config DSL or shell scripts\n‚Ä¢ \tValidate syntax, suggest corrections, and explain errors\nWhy it matters: Jarvis becomes a true debugging companion.\n\nüßô‚Äç‚ôÄÔ∏è 8. Magical Personality Engine\nUse a tone controller to:\n‚Ä¢ \tShift between playful, serious, or motivational modes\n‚Ä¢ \tRespond with magical metaphors or themed encouragement\n‚Ä¢ \tOffer ‚Äúspells‚Äù (shortcuts) for common tasks\nWhy it matters: Makes Jarvis delightful and emotionally engaging.\n\nüß≠ 9. Goal-Oriented Planning via LangGraph\nUse LangGraph to:\n‚Ä¢ \tBuild branching workflows (e.g., ‚ÄúIf quiz score < 70%, re-explain‚Äù)\n‚Ä¢ \tHandle retries, clarifications, and tool chaining\nWhy it matters: Jarvis can guide students through learning journeys with logic and care.\n\nEnsure all changes maintain the magical, encouraging personality of a real-life Iron Man JARVIS while adding enterprise-grade intelligence. Focus on making Jarvis adaptive, contextually aware, and capable of handling complex student interactions with clarity and warmth."
  }
}